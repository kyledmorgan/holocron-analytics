# SQL Evidence Packaging - Phase 2

## Overview

SQL result sets are a key evidence source for LLM interrogations. Phase 2 provides robust, deterministic packaging of SQL query results into bounded, text-based evidence items that LLMs can process.

## Two Operating Modes

### Mode D1: SQL Results Already Exist (Preferred MVP)

Load pre-executed query results from lake artifacts.

**When to use:**
- Results were generated by the ingest pipeline
- Running queries is not safe in the context
- Results are already persisted and versioned

**Process:**
1. Job references a lake artifact containing SQL results
2. Evidence builder loads the artifact
3. Results are formatted as bounded text
4. Full result set remains in lake (referenced via `full_ref`)

### Mode D2: Execute SQL Query (Optional, Guarded)

Execute a SQL query at evidence build time.

**When to use:**
- Dynamic queries based on job inputs
- Results need to be fresh at interrogation time
- Safe, read-only database access is available

**Guardrails:**
- **SELECT-only** - Only SELECT statements allowed (basic validation)
- **Timeout** - Query timeout enforced (default: 30 seconds)
- **Read-only connection** - Prefer read-only credentials if available
- **Query logging** - Full query text persisted as artifact

## SQL Result Artifact Format

SQL results should be stored as JSON artifacts with this structure:

```json
{
  "columns": ["col1", "col2", "col3"],
  "rows": [
    [val1, val2, val3],
    [val4, val5, val6]
  ],
  "row_count": 2,
  "query": "SELECT col1, col2, col3 FROM table WHERE ..."
}
```

**Alternative:** Results can also be row-wise dictionaries:
```json
{
  "columns": ["name", "age"],
  "rows": [
    {"name": "Alice", "age": 30},
    {"name": "Bob", "age": 25}
  ],
  "row_count": 2
}
```

## Bounded Text Representation

SQL results are converted to readable text for the LLM:

```
SQL Result Set (10000 rows, 50 columns)
Columns: id, name, species, homeworld, birth_year

(Note: Showing 20 of 50 columns)

Sampling: First 50 and last 50 rows of 10000

Row 0: {"id": 1, "name": "Luke Skywalker", "species": "Human", ...}
Row 1: {"id": 2, "name": "Leia Organa", "species": "Human", ...}
...
Row 49: {"id": 50, ...}
Row 9950: {"id": 9951, ...}
...
Row 9999: {"id": 10000, ...}
```

## Bounding Rules

SQL results are bounded by:

1. **Row Limit** (`max_sql_rows` in policy, default: 100)
2. **Column Limit** (`max_sql_cols` in policy, default: 20)
3. **Item Byte Limit** (`max_item_bytes` in policy, default: 10,000)

### Row Sampling Strategies

When result sets exceed `max_sql_rows`, use deterministic sampling:

#### first_only
Include only the first N rows.

**Use when:** Rows are ordered by importance (e.g., `ORDER BY score DESC`)

```
Sampling: First 100 rows of 10000
Row 0: ...
Row 1: ...
...
Row 99: ...
```

#### first_last (default)
Include first N/2 and last N/2 rows.

**Use when:** Both head and tail are informative (e.g., time series data)

```
Sampling: First 50 and last 50 rows of 10000
Row 0: ...
Row 49: ...
Row 9950: ...
Row 9999: ...
```

#### stride
Sample every Kth row where K = total_rows / max_rows.

**Use when:** Representative sampling across the full range is needed

```
Sampling: Every 100th row (sampled 100 of 10000)
Row 0: ...
Row 100: ...
Row 200: ...
...
```

### Column Truncation

If result sets have many columns, only the first `max_sql_cols` are included:

```
SQL Result Set (1000 rows, 75 columns)
Columns: col1, col2, col3, ..., col20

(Note: Showing 20 of 75 columns)
```

**Best Practice:** Order columns by importance in the SELECT clause so that the most relevant columns appear first.

## Evidence Item Metadata

SQL result evidence items include detailed metadata:

```json
{
  "evidence_id": "sql:query_abc:0",
  "evidence_type": "sql_result",
  "source_ref": {
    "lake_uri": "results/query_abc.json",
    "query_key": "character_facts",
    "query": "SELECT id, name, species FROM characters WHERE ..."
  },
  "content": "SQL Result Set (1000 rows, 10 columns)...",
  "content_sha256": "...",
  "byte_count": 8500,
  "metadata": {
    "bounding": {
      "applied": true,
      "original_size": 250000,
      "bounded_size": 8500
    },
    "sql_meta": {
      "total_rows": 1000,
      "total_cols": 10,
      "sampled_rows": 100,
      "sampled_cols": 10,
      "sampling_strategy": "first_last",
      "sampling_note": "First 50 and last 50 rows of 1000",
      "cols_truncated": false
    },
    "query_key": "character_facts"
  },
  "full_ref": {
    "lake_uri": "results/query_abc.json",
    "row_count": 1000,
    "col_count": 10
  }
}
```

## Mode D1: Loading Existing Results

```python
from llm.evidence.sources.sql_result_source import load_sql_result_evidence
from llm.contracts.evidence_contracts import EvidencePolicy

policy = EvidencePolicy(max_sql_rows=50, sampling_strategy="first_only")

sql_result_refs = [
    {
        "lake_uri": "llm_runs/2024/01/15/query_results.json",
        "query_key": "entity_facts",
        "metadata": {"description": "Entity fact extraction query"}
    }
]

items = load_sql_result_evidence(sql_result_refs, policy, lake_root="lake")
```

## Mode D2: Executing Queries

```python
from llm.evidence.sources.sql_result_source import execute_sql_query
from llm.contracts.evidence_contracts import EvidencePolicy

policy = EvidencePolicy(max_sql_rows=100)

query = """
SELECT entity_id, entity_name, entity_type, fact_key, fact_value
FROM entities e
JOIN entity_facts f ON e.id = f.entity_id
WHERE e.entity_type = 'character'
ORDER BY e.entity_name
"""

item = execute_sql_query(
    query=query,
    connection_string="DRIVER={...};SERVER=localhost;DATABASE=Holocron;...",
    query_key="character_facts",
    policy=policy,
    timeout_seconds=30
)
```

**Security Note:** The `execute_sql_query` function validates that the query starts with `SELECT`. This is a basic safeguard; consider additional validation in production.

## SQL Query Definitions as Evidence

Optionally include query definitions as evidence items to provide transparency:

```python
from llm.evidence.sources.sql_query_source import load_sql_query_definitions

query_defs = [
    {
        "query_key": "character_facts",
        "query": "SELECT id, name, species FROM characters WHERE ...",
        "description": "Retrieve character facts for analysis"
    }
]

items = load_sql_query_definitions(query_defs, policy)
```

This creates evidence items showing what queries were run, which helps the LLM understand the source of the data.

## Integration with Evidence Bundle Builder

The evidence builder automatically handles SQL evidence when provided in `evidence_refs`:

```python
from llm.evidence.builder import build_evidence_bundle

evidence_refs = {
    "sql_results": [
        {
            "lake_uri": "results/query1.json",
            "query_key": "character_data"
        },
        {
            "lake_uri": "results/query2.json",
            "query_key": "planet_data"
        }
    ],
    "sql_queries": [
        {
            "query_key": "character_data",
            "query": "SELECT ...",
            "description": "Character facts"
        }
    ]
}

bundle = build_evidence_bundle(job_input, evidence_refs, policy)
```

## Best Practices

1. **Pre-compute results when possible** - Use Mode D1 for reproducibility
2. **Order important columns first** - Column truncation keeps the first N
3. **Order important rows first** - Use `first_only` sampling with meaningful ORDER BY
4. **Avoid SELECT \*** - Explicitly list columns you need
5. **Use read-only connections** - For Mode D2, use credentials with minimal permissions
6. **Set appropriate timeouts** - Prevent long-running queries from blocking
7. **Log all queries** - Always persist query text as an artifact for auditability
8. **Test sampling strategies** - Verify sampling produces representative results

## Limitations and Future Work

**Current Limitations:**
- Basic SELECT-only validation (regex-based)
- No query complexity analysis
- No automatic query optimization
- Limited column type handling

**Phase 3+ Enhancements:**
- Semantic query validation
- Query cost estimation
- Smart column selection based on relevance
- Type-aware formatting (dates, JSON, etc.)
- Query result caching layer

## See Also

- [Evidence Bundles](evidence.md) - Overall evidence system
- [Phase 1 Runner](phase1-runner.md) - How evidence bundles are consumed
- [LLM-Derived Data](derived-data.md) - Subsystem vision
