# PR #15: Refactor state store: SQLite → SQL Server (Docker) + deprecation docs

## Header

| Field | Value |
|---|---|
| **PR Number** | 15 |
| **Title** | Refactor state store: SQLite → SQL Server (Docker) + deprecation docs |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/15 |
| **State** | merged |
| **Created** | 2026-01-21T22:29:53Z |
| **Updated** | 2026-01-21T22:48:43Z |
| **Merged** | 2026-01-21T22:48:42Z |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/refactor-sqlite-to-sql-server` |
| **Merge commit SHA** | `f1ddd85bb64830f15e317cdebc892d78b64f0b8d` |

---

## PR Body

Migrates the ingestion framework's state store backend from SQLite to SQL Server for production workloads. SQLite remains available but deprecated.

## Changes

### New SQL Server Backend (`src/ingest/state/sqlserver_store.py`)
- Implements `StateStore` interface with pyodbc
- Auto-creates `ingest` schema and `work_items` table
- Adds `get_known_resources()` and `reset_for_recrawl()` for re-crawl without re-seeding
- Strict SQL identifier validation (regex + reserved word blocking)

### Backend Selection
- Factory function `create_state_store(backend=...)` in `state/__init__.py`
- `DB_BACKEND` env var controls selection (default: `sqlserver`)
- SQLite emits `DeprecationWarning` when used

### Documentation
- `docs/deprecated/sqlite-state-store.md`: Full schema DDL, workflow diagrams, reintroduction instructions
- `docs/sqlserver-backend.md`: Setup, configuration, dedupe/re-crawl patterns, troubleshooting

### Smoke Test
- `scripts/db/db_smoketest.py`: Verifies connectivity, schema creation, CRUD, dedupe

## Usage

```python
from ingest.state import create_state_store

# Default: SQL Server
store = create_state_store()

# Explicit SQLite (deprecated)
store = create_state_store(backend="sqlite", db_path="local/state.db")
```

```bash
# Environment configuration
export DB_BACKEND=sqlserver
export MSSQL_SA_PASSWORD="YourPassword"

# Verify connectivity
python scripts/db/db_smoketest.py
```

<!-- START COPILOT CODING AGENT SUFFIX -->



<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

# Copilot Agent Prompt — Refactor SQLite → SQL Server (Docker) + Deprecation Docs

You are operating inside an existing Python ingestion/crawling codebase that currently uses **SQLite** for state/runs/deduping (and possibly other metadata). The project has “runners” (e.g., an `IngestRunner`-style orchestration), connectors/discovery modules (e.g., OpenAlex, MediaWiki/Wookieepedia), and a storage layer (e.g., file lake writer). The system has already successfully stood up a **local Docker SQL Server container/image** and we want to **migrate off SQLite** as the default execution-state database.

## Primary Objectives (Deliverables Required)
1. **Refactor the codebase to stop using SQLite and instead use SQL Server** (running in local Docker) as the primary backend for:
   - run tracking (runs/batches)
   - state store / checkpointing
   - dedupe / “already seen” resource tracking
   - any queue/seed/discovery link tracking currently persisted in SQLite
2. **Produce a highly verbose, complete Markdown document** that captures the full “SQLite era” implementation:
   - architecture and rationale
   - schema/tables (DDL, columns, indexes, constraints)
   - how SQLite related to runners/orchestration, connectors, discovery, storage
   - operational workflow: how runs were created, how dedupe worked, how checkpoints were stored
   - limitations, known issues, and why we are migrating
   - how to reintroduce SQLite in the future if ever needed
   - label the SQLite approach as **deprecated/defunct** (use common terminology: “Deprecated” + “Removed from default path”)
3. Provide a clear **path-forward** doc section that explains how SQL Server supports:
   - multiple source categories (MediaWiki/Wookieepedia/Wikipedia, OpenAlex, future APIs, HTTP endpoints)
   - idempotency + dedupe
   - optional “re-crawl” without re-seeding (we can re-fetch known resources by direct query)
   - versioned result sets / run lineage

## Constraints / Non-Goals
- Do **not** optimize for performance beyond “reasonable defaults.” Use typical indexing/constraints; no partitioning complexity required beyond a **schema prefix or naming prefix** convention that keeps tables logically grouped.
- We can punt on backup/retention/DBA policies for now.
- Avoid broad folder renames/refactors. Only add what’s needed to support this migration and documentation.
- Keep changes **incremental and reviewable** in a single PR if possible.

---

## Step 1 — Inventory Current SQLite Usage (Must Be Explicit)
Perform a repository-wide audit and produce a short internal note (in PR description or `docs/` note) listing:
- all modules importing/using `sqlite3` or any SQLite wrapper
- any “SqliteStateStore” or equivalent
- any DDL scripts, `.db` files, or initialization code
- any unit/integration tests that depend on SQLite

Then map each SQLite responsibility to an SQL Server equivalent.

---

## Step 2 — Introduce a Database Abstraction Layer (If Not Already Present)
If the project already has a “state store” interface, extend it. If not, create one.

Create an interface/protocol such as:
- `StateStore` (checkpointing + run metadata)
- `DedupeStore` (seen/processed resources)
- `QueueStore` (optional seed queue, discovered links)
You may consolidate these if the current code has a single SQLite class doing everything, but keep responsibilities clear.

### Required Outcome
- SQLite implementation becomes **non-default** (deprecated path).
- SQL Server implementation becomes the **default** backend for runners.

---

## Step 3 — SQL Server Implementation
### 3.1 Connection / Driver
Use a practical Python approach compatible with Docker SQL Server:
- Preferred: `pyodbc` (common with SQL Server), or `pymssql` if already used.
- If the repo already uses SQLAlchemy, use SQLAlchemy with a SQL Server driver.
Do not introduce heavy new dependencies unless justified.

### 3.2 Configuration
Add configuration that supports local Docker SQL Server by environment variables and/or YAML:
- `DB_BACKEND=sqlserver` (default)
- `SQLSERVER_HOST`, `SQLSERVER_PORT`, `SQLSERVER_DATABASE`
- `SQLSERVER_USERNAME`, `SQLSERVER_PASSWORD`
- optional: `SQLSERVER_SCHEMA` (default e.g. `ingest` or `holocron_ingest`)
Ensure secrets are not committed.

### 3.3 Schema Conventions (Simple Partitioning)
Implement one of these conventions (choose one and apply consistently):
- **Schema-based**: `ingest.*` tables (recommended)
- **Name prefix**: `ingest_` prefix for all tables

Add the minimal DDL required, idempotently.

### 3.4 Minimal “Typical” Indexing / Constraints
We need dedupe and idempotency. Implement:
- unique constraints on the “resource identity” keys (e.g., `(source_system, external_id)` or `(source_system, canonical_url)` depending on current model)
- an index on run/batch foreign keys
- an index on “status” or “last_seen_at” columns if used by re-crawl logic

---

## Step 4 — Data Model Migration (Derive From Existing SQLite Tables)
Do NOT invent a brand-new domain model unless ...

</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

✨ Let Copilot coding agent [set things up for you](https://github.com/kyledmorgan/holocron-analytics/issues/new?title=✨+Set+up+Copilot+instructions&body=Configure%20instructions%20for%20this%20repository%20as%20documented%20in%20%5BBest%20practices%20for%20Copilot%20coding%20agent%20in%20your%20repository%5D%28https://gh.io/copilot-coding-agent-tips%29%2E%0A%0A%3COnboard%20this%20repo%3E&assignees=copilot) — coding agent works faster and does higher quality work when set up for your repo.

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
