# PR #35: Add Semantic Staging (SourcePage + Signals + Classification + Promotion + Tags)

## Header

| Field | Value |
|---|---|
| **PR Number** | 35 |
| **Title** | Add Semantic Staging (SourcePage + Signals + Classification + Promotion + Tags) |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/35 |
| **State** | merged |
| **Created** | 2026-02-06T23:45:18Z |
| **Updated** | 2026-02-07T00:04:46Z |
| **Merged** | 2026-02-07T00:04:46Z |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/add-semantic-staging-phase` |
| **Merge commit SHA** | `278272b94c219485e42c283410371abf7d59e5dc` |

---

## PR Body

Adds a semantic staging phase to classify ingested wiki pages by type and stage them for promotion into `dbo.DimEntity`. Uses title patterns, minimal content signals, and optional LLM classification.

## Database Schema

- **`sem` schema** with three tables:
  - `SourcePage` ‚Äî page identity bridging to ingest records
  - `PageSignals` ‚Äî extracted cues (lead sentence, infobox type, categories, flags)
  - `PageClassification` ‚Äî type inference with LLM run lineage

- **`dbo.DimEntity` extensions**: `PromotionState`, `SourcePageId`, `PrimaryTypeInferred`, `TypeSetJsonInferred`, `AdjudicationRunId`

- **Tag system**: `DimTag`, `BridgeTagAssignment`, `BridgeTagRelation`

- **Views**: `sem.vw_CurrentPageClassification`, `sem.vw_EntityCandidates`, `dbo.vw_PromotedEntities`, etc.

## Python Module (`src/semantic/`)

- **RulesClassifier** ‚Äî Stage 0: namespace detection, continuity suffix, title patterns
- **SignalsExtractor** ‚Äî Stage 1: lead sentence, infobox type, categories
- **PageRouter** ‚Äî orchestrates stages, determines if LLM needed
- **SemanticStagingStore** ‚Äî SQL persistence layer

## LLM Integration

Added `page_classification_v1` interrogation definition with taxonomy:
- In-universe: `PersonCharacter`, `LocationPlace`, `WorkMedia`, `EventConflict`, `Organization`, `Species`, etc.
- Meta: `MetaReference`, `TimePeriod`, `TechnicalSitePage`

## Usage

```bash
python -m src.semantic.cli classify "Anakin Skywalker"
# Namespace: main, Continuity: unknown, needs signals/LLM

python -m src.semantic.cli classify "Module:ArchiveAccess/SW"
# TechnicalSitePage, confidence: 1.0, complete via rules

python -m src.semantic.cli classify "Timeline of galactic history"
# MetaReference, confidence: 0.95, complete via rules
```

Promotion states: `staged` ‚Üí `candidate` ‚Üí `adjudicated` ‚Üí `promoted` | `suppressed` | `merged`

<!-- START COPILOT CODING AGENT SUFFIX -->



<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

# Copilot Agent Mode ‚Äî Semantic Staging (SourcePage + Signals + Classification + Promotion + Tags)

## Context / Intent (read first)
We have already ingested a large number of wiki-style pages (e.g., Wookieepedia). The content exists in `ingest.IngestRecords` as semi-structured payload blobs (HTML/wikitext/JSON depending on variant). We also have an LLM orchestration framework in-repo (Ollama/local models + LLM-neutral job/run/artifact tables) that we want to reuse.

**Goal of this work:** add a new ‚Äúsemantic staging‚Äù phase that classifies each *page* at a shallow level (mostly using the page title; optionally peeking at a small amount of content like lead sentence / infobox type / categories) to infer what the page ‚Äúis‚Äù (character, location, work, event, concept, meta page, etc.) and to stage/prompt promotion into `dbo.DimEntity` via an adjudication/promotions state.

This is **local-only** (no online calls). We will process pages initially **one-by-one**; parallelization is out of scope (but design should not block future parallelism).

## Your responsibility as the agent
1) **Reconcile schema names** listed below with what actually exists in the database.
2) Use existing tables wherever possible.
3) Determine what does NOT exist and needs to be created (tables/columns/indexes/FKs/views/procs).
4) Implement database changes and minimal pipeline scaffolding in the repo to support the new stage.
5) Keep the design compatible with the existing LLM job/run framework and promotion model.

---

## What we believe exists today (inventory; reconcile against actual DB)

### Ingest
- `ingest.IngestRecords` (has resource_id/title, payload, hash_sha256, fetched_at_utc, run_id, variant, content_type, etc.)
- `ingest.work_items`, `ingest.ingest_runs`, and views like `ingest.vw_LatestSuccessfulFetch`, `ingest.vw_WorkItems_Recent`

### LLM orchestration / lineage
- `llm.job` (job queue; input_json; interrogation_key; evidence_ref_json; model_hint; etc.)
- `llm.run` (run records; model_name/tag/digest; metrics_json; status; etc.)
- `llm.artifact` (artifacts emitted by runs; lake_uri; sha256; etc.)
- `llm.evidence_bundle`, `llm.evidence_item`, `llm.run_evidence`
- `llm.source_registry` (source identity for indexing; content_sha256; chunk_count; tags_json; etc.)
- `llm.chunk`, `llm.embedding`, `llm.retrieval`, `llm.retrieval_hit`

### Canonical dimensional model (examples)
- `dbo.DimEntity` (EntityKey/Guid, FranchiseKey, EntityType, DisplayName, normalized names, aliases, confidence, canonical flags, SCD2 columns, AttributesJson, SourceSystem/SourceRef/IngestBatchId, etc.)
- Multiple `dbo.Dim*` and `dbo.Fact*` tables: Character/Location/Work/Species/Event/Claim/ContinuityFrame/etc.
- ‚ÄúSemantic‚Äù tables under `dbo.sem_*` (e.g., `dbo.sem_character`, `dbo.sem_location`, `dbo.sem_event`, etc.) and marts `dbo.mart_*`
- Bridge tables like `dbo.BridgeEventParticipant`, `dbo.BridgeEventAsset`, `dbo.BridgeContinuityIssueClaim`

---

## What we want to build (feature request)

### A) Page-level semantic staging (3 new tables)
Add three new tables (names can be adjusted to fit naming conventions, but keep these concepts):

1) **Source Page** (page identity + provenance)
   - Proposed: `sem.SourcePage`
   - Represents a ‚Äúpage/article‚Äù identity derived from ingest + registry.
   - Bridges to:
     - latest fetch: `ingest.IngestRecords.ingest_id`
     - optional indexing: `llm.source_registry.source_id`
   - Captures `SourceSystem`, `ResourceId` (title), `Variant`, `Namespace`, `ContinuityHint`, `ContentHashSha256`, timestamps.

2) **Page Signals** (cheap extracted cues; minimal content peek)
   - Proposed: `sem.PageSignals`
   - One row per SourcePage (or versioned if needed).
   - Stores small fields like:
     - LeadSentence (or first N chars)
     - InfoboxType (if derivable)
     - CategoriesJson (top categories)
     - Flags: IsListPage, IsDisambiguation, HasTimelineMarkers
     - SignalsJson for extras (section headers sample, etc.)

3) **Page Classification** (type inference + lineage)
   - Proposed: `sem.PageClassification`
   - Many rows over time per SourcePage (taxonomy_version + run lineage).
   - Stores:
     - PrimaryType (e.g., PersonCharacter / LocationPlace / WorkMedia / EventConflict / Concept / MetaReference / TechnicalSitePage / TimePeriod)
     - TypeSetJson (multi-label with weights)
     - ConfidenceScore
     - Method (rules/llm/hybrid)
     - ModelName/PromptVersion
     - RunId (FK to `llm.run`)
     - EvidenceJson (explainability + used signals)

### B) Promotion/adjudication state on DimEntity (reuse existing table)
We want to treat `dbo.DimEntity` as the single entity table where ‚Äúanything can land,‚Äù but it should not be visible/used downstream until adjudicated/promoted.

**Add columns to `dbo.DimEntity`** (reconcile names; add if missing):
- `PromotionState` nvarchar(30) NOT NULL DEFAULT 'staged'
  - allowed: staged | candidate | adjudicated | promoted | suppressed | merged
- `PromotionDecisionUtc` datet...

</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

üí¨ We'd love your input! Share your thoughts on Copilot coding agent in our [2 minute survey](https://gh.io/copilot-coding-agent-survey).

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
