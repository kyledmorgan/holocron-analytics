# PR #19: Add SQL Server schema provisioning and local E2E test suite

## Header

| Field | Value |
|---|---|
| **PR Number** | 19 |
| **Title** | Add SQL Server schema provisioning and local E2E test suite |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/19 |
| **State** | merged |
| **Created** | 2026-01-21T22:52:06Z |
| **Updated** | 2026-01-21T23:08:58Z |
| **Merged** | 2026-01-21T23:08:58Z |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/add-sql-server-schema-test-suite` |
| **Merge commit SHA** | `45c122409205fb75e3da1431343ddd72c47914d5` |

---

## PR Body

Adds idempotent database migrations and a local test suite that validates SQL Server ingestion end-to-end without external network dependencies.

### Schema Provisioning

- `db/migrations/` — Versioned SQL scripts (schema, tables, indexes)
- `tools/db_init.py` — Python entrypoint with wait-for-ready and SQL identifier validation

```bash
python -m tools.db_init --migrations-dir db/migrations
```

### Test Suite

- `tests/unit/` — 20 unit tests, no external deps
- `tests/integration/` — Schema/table verification, CRUD ops
- `tests/e2e/` — Full pipeline tests with dedupe verification

### Test Connector

- `src/ingest/connectors/test_connector.py` — Deterministic connector returning synthetic data
- Exercises same pipeline path as production connectors

### Execution Targets

```bash
make verify-sqlserver   # One command: start → init → smoke → tests
make test-unit          # Fast, no SQL Server required
make test-integration   # Requires SQL Server
make test-e2e           # Full pipeline
```

### Documentation

Updated `docs/sqlserver-backend.md` with "Running Tests Locally" and "Database Migrations" sections.

<!-- START COPILOT CODING AGENT SUFFIX -->



<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

# Copilot Agent Addendum — SQL Server Schema + Local E2E Test Suite

This addendum extends the prior prompt. It adds two non-negotiable deliverables:
1) **SQL Server schema/table provisioning for ingestion** (if not already present), and  
2) a **local runnable test suite** (including at least one end-to-end integration path) that proves data flows into SQL Server and lands in the correct tables.

---

## New Primary Objectives (Additive Deliverables)
### A. SQL Server Schema + Tables Provisioning (Idempotent)
- Ensure the SQL Server database has an explicit **ingestion schema** (preferred) or table-name prefix (acceptable).
- The schema/tables must be created **automatically** and **idempotently**:
  - either during application startup (runner init),
  - or via a dedicated “migrate/init” command,
  - and also callable from tests.

**Required capabilities:**
- Create schema if missing (e.g., `CREATE SCHEMA ingest`).
- Create tables if missing.
- Add constraints and indexes if missing (or guarded by existence checks).
- Avoid destructive operations by default (no drop/recreate unless explicitly requested).

**Artifacts to include:**
- A versioned SQL script set under something like `db/migrations/` or `db/sqlserver/`:
  - `0001_create_schema.sql`
  - `0002_create_tables.sql`
  - `0003_indexes_constraints.sql`
- A Python entrypoint to apply these scripts:
  - `python -m tools.db_init` (or similar)
  - Must support environment/config-based connection settings.

---

## B. Local Test Suite (Unit + Integration + E2E Smoke)
We need an executable test suite that can be run locally to validate:
- SQL Server is reachable
- ingestion schema/tables are present (or created)
- runner(s) can execute against SQL Server
- end-to-end flow inserts the correct entities into the correct tables
- dedupe/idempotency works (re-run does not duplicate)

### B1. Test Framework + Layout
Use existing framework if present; otherwise standardize on `pytest`.

Create/confirm structure:
- `tests/unit/` — no external DB required
- `tests/integration/` — requires SQL Server (Docker) running
- `tests/e2e/` — optional, but include at least one end-to-end test that exercises runner + store + a minimal connector/discovery stub

Add a clear doc section in `docs/sqlserver-backend.md`:
- how to run unit tests
- how to run SQL Server integration tests
- how to run E2E tests

### B2. Test Execution Targets
Add one or more of the following:
- `Makefile` targets:
  - `make test`
  - `make test-unit`
  - `make test-sqlserver` (integration)
  - `make test-e2e`
- or `scripts/` equivalents:
  - `./scripts/test_unit.sh`
  - `./scripts/test_sqlserver.sh`

Avoid introducing heavy toolchains if not needed.

---

## C. Docker-Assisted Test Environment
Tests must be runnable locally with minimal friction.

### Required: Compose + Health + Wait
If `docker-compose.yml` is already present, extend it. Otherwise add it. Must include:
- SQL Server service
- healthcheck
- a named volume (recommended)

Add a “wait until ready” mechanism for tests:
- either rely on healthcheck + `docker compose wait`
- or a lightweight Python-based retry loop in the test harness

---

## D. Schema/DDL Verification (Tests Must Assert Correct Tables)
Integration/E2E tests must verify, at minimum:
1) Schema exists (e.g., `ingest`)
2) Required tables exist in that schema
3) A minimal run inserts expected rows in the expected tables
4) A second run demonstrates dedupe behavior

### Concrete Assertions (Examples — adapt to actual table names)
- `SELECT 1 FROM sys.schemas WHERE name='ingest'`
- `SELECT 1 FROM sys.tables t JOIN sys.schemas s ON t.schema_id=s.schema_id WHERE s.name='ingest' AND t.name IN (...)`
- Run an ingestion operation, then:
  - assert `ingest_runs` has 1 row for that run
  - assert `ingest_records` (or equivalent) has N rows
  - assert `seen_resources` has N rows
  - rerun the same workload and confirm row counts remain stable (or only expected metadata changes)

---

## E. E2E Test Design (Do Not Depend on External Internet)
The end-to-end test must not rely on live Wikipedia/OpenAlex endpoints.

Implement a deterministic “test connector”:
- `connectors/test_connector.py` (or similar)
- returns a small, fixed dataset of synthetic resources (IDs + titles + URLs)
- exercises the same pipeline path as production connectors, but is deterministic

The test should run the runner against this connector and verify SQL Server persistence.

---

## F. Tooling: One Command “Prove It Works”
Add a single local command that:
1) starts SQL Server container (if needed)
2) initializes schema/tables
3) runs integration/E2E tests
4) prints a concise pass/fail summary

Example:
- `make verify-sqlserver`
or
- `./scripts/verify_sqlserver.sh`

---

## Definition of Done (Addendum)
1) There is a repeatable, local **test command** to validate SQL Server ingestion end-to-end.
2) There is at least one deterministic **E2E test** that exercises runner → store → SQL Server tables, with no external ...

</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

✨ Let Copilot coding agent [set things up for you](https://github.com/kyledmorgan/holocron-analytics/issues/new?title=✨+Set+up+Copilot+instructions&body=Configure%20instructions%20for%20this%20repository%20as%20documented%20in%20%5BBest%20practices%20for%20Copilot%20coding%20agent%20in%20your%20repository%5D%28https://gh.io/copilot-coding-agent-tips%29%2E%0A%0A%3COnboard%20this%20repo%3E&assignees=copilot) — coding agent works faster and does higher quality work when set up for your repo.

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
