# PR #41: Add retry logic and resilience for Ollama JSON parsing failures

## Header

| Field | Value |
|---|---|
| **PR Number** | 41 |
| **Title** | Add retry logic and resilience for Ollama JSON parsing failures |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/41 |
| **State** | merged |
| **Created** | 2026-02-08T04:11:29Z |
| **Updated** | 2026-02-08T04:27:54Z |
| **Merged** | 2026-02-08T04:27:54Z |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/make-ollama-json-parsing-resilient` |
| **Merge commit SHA** | `30a47d793b3d9a079dca2337aaae3dbc860cf130` |

---

## PR Body

Runner terminates when Ollama returns malformed JSON, killing entire batch jobs. This adds 3-attempt retry with exponential backoff (250msâ†’1s, jittered) and multiple parsing strategies (direct, stripped, embedded extraction).

## Changes

### New Components
- **`InvalidOllamaJsonError`** - Specific exception for JSON parse failures, captures raw content and attempt count
- **`src/llm/utils/retry.py`** - Retry utilities with configurable backoff and multi-strategy JSON parsing
- **`LakeWriter.write_artifact()`** - Generic binary artifact writer for error payloads

### Modified Behavior
- **Phase1Runner** - Wraps Ollama calls in retry loop, writes error manifests on exhaustion, marks job failed but continues
- **dry_run_page_classification.py** - Same retry pattern for CLI usage

### Error Artifacts
On failure after retries, writes:
- `invalid_json_response.txt` - Raw text from Ollama
- `error_manifest.json` - Metadata: attempts, error history, decision

## Example

```python
# Before: Job fails, runner dies
response = client.chat_with_structured_output(messages, schema)
parsed = json.loads(response.content)  # JSONDecodeError kills runner

# After: Retry with backoff, fallback strategies, continue on failure
for attempt in range(3):
    response = client.chat_with_structured_output(messages, schema)
    try:
        parsed = self._parse_and_validate(response, interrogation)
        break  # Success
    except InvalidOllamaJsonError:
        if attempt < 2:
            time.sleep(calculate_delay(attempt, config))
        else:
            write_error_artifacts()
            mark_failed(job_id)
            return  # Continue to next job
```

JSON parsing strategies:
1. Direct `json.loads(content)`
2. Strip whitespace `json.loads(content.strip())`
3. Extract embedded `{...}` from text (conservative bracket matching)

## Test Coverage
- 19 tests for retry utilities
- 4 integration tests for runner resilience
- All 247 existing LLM tests pass

<!-- START COPILOT CODING AGENT SUFFIX -->



<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

> # Copilot Agent Task â€” Make Ollama JSON parsing resilient (retry + skip + log)
> 
> ## Context
> Our runner (Holocron Analytics) processes hundreds/thousands of records and calls Ollama, writing request/response artifacts under `logs\ollama\`.
> The runner currently **dies** when it hits: **"Ollama returned invalid JSON."**
> We need resilience: only truly fatal errors should stop the job. Invalid JSON should not crash the whole run.
> 
> Example log snippet:
> - `Wrote Ollama response: logs\ollama\20260208_021510_Leia_Skywalker_Organa_Solo_response.json`
> - then: `Ollama returned invalid JSON.` (runner terminates)
> 
> ## Goal
> Update the pipeline so that invalid JSON from Ollama is handled gracefully:
> 1) **Retry up to 3 times** to obtain valid JSON.
> 2) Use a **backoff** between retries (e.g., 250ms â†’ 1s jittered; Copilot choose best pattern).
> 3) If still invalid after retries:
>    - **do not crash the runner**
>    - mark the record as failed/flagged in the most appropriate way given our current state tracking design
>    - move on to the next record
> 4) Ensure we preserve evidence for troubleshooting:
>    - write the raw response body (as text) even if invalid JSON
>    - write a small â€œerror manifestâ€ alongside the response (or add to the existing structured log) containing:
>      - record identifier(s)
>      - attempt count
>      - exception details
>      - whether it was skipped or left in queue / will retry later
> 
> ## Implementation Guidance (let you decide best based on current codebase)
> - Identify where we currently:
>   - call Ollama (HTTP client or SDK)
>   - parse/validate JSON
>   - raise the fatal exception
> - Wrap the **JSON parse + validation** boundary in a retry loop.
> - â€œValid JSONâ€ means:
>   - `json.loads(...)` succeeds (Python) or equivalent
>   - AND (if we have a schema/expected keys) the payload matches minimum expected shape
> - If Ollama sometimes returns extra text before/after JSON:
>   - consider robust extraction:
>     - trim whitespace
>     - if response contains a JSON object embedded in text, attempt to extract the first `{...}` block safely
>     - but do NOT overfit; keep it conservative and log when extraction is used
> - Add a clear, explicit error class like `InvalidOllamaJsonError` so we can track stats.
> - Ensure the runner continues and marks status appropriately:
>   - If we have a state table/queue: set status = failed (reason = invalid_json) OR increment error_count and keep in queue depending on current design
>   - Avoid infinite loops: respect max retries and optionally add â€œcooldownâ€ for the item
> 
> ## Acceptance Criteria
> - Runner no longer terminates on invalid JSON.
> - A single item can fail after 3 retries without stopping the whole batch.
> - Logs show:
>   - attempt number
>   - why parse failed
>   - what decision was taken (retry / skip / leave pending)
> - Unit or lightweight integration test added:
>   - simulate invalid JSON response
>   - confirm 3 retries occur
>   - confirm job continues and item is flagged
> 
> ## Deliverables
> - Code changes (minimal invasive) implementing retry+skip behavior.
> - Test(s) and/or a small harness that simulates invalid JSON from Ollama.
> - Updated docs/README snippet (optional) describing resilience behavior and where to look for failure artifacts.


</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

ðŸ’¡ You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
