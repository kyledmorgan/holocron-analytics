# PR #25: [WIP] Implement phase 2 of evidence assembly in holocron-analytics

## Header

| Field | Value |
|---|---|
| **PR Number** | 25 |
| **Title** | [WIP] Implement phase 2 of evidence assembly in holocron-analytics |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/25 |
| **State** | closed |
| **Created** | 2026-01-24T05:13:14Z |
| **Updated** | 2026-01-24T05:13:52Z |
| **Merged** | _N/A_ |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/implement-evidence-assembly-phase-2` |
| **Merge commit SHA** | `88fddeb4447e2cc546caf30a650df3799a120fad` |

---

## PR Body

Thanks for asking me to work on this. I will get started on it and keep this PR's description up to date as I form a plan and make progress.


<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

> [!IMPORTANT]
> # Copilot Agent Brief (Verbose) â€” Implement Phase 2: Evidence Assembly + Packaging (Internal Docs + SQL Result Sets + Raw Artifacts)
>
> ## Audience and Intent
> You are GitHub Copilot running in Agent Mode. This brief defines work for a **single PR** to implement **Phase 2** of the LLM-Derived Data subsystem in `holocron-analytics`.
>
> Phase 2 focus: **Evidence Assembly** â€” building deterministic, bounded, and auditable **evidence bundles** that feed Phase 1â€™s runner (LLM calls with strict JSON outputs).
>
> We are running locally:
> - Windows host OS
> - WSL2 + Docker Desktop
> - Ollama running in Docker (already in progress / partially implemented)
> - SQL Server in Docker (system-of-record)
> - Lake/artifacts persisted via a Docker volume (filesystem)
>
> This PR must remain **evidence-layer focused**. Do not implement vector embeddings / RAG retrieval (Phase 3) and do not implement web retrieval (Phase 4).
>
> ---
>
> # 1) Phase 2 Definition (What â€œDoneâ€ means)
>
> Phase 2 delivers a robust, extensible **Evidence Bundle Builder** that can:
> 1) Build evidence bundles from:
>    - direct inline evidence (provided in job payload),
>    - references to lake artifacts (raw HTTP, docs, transcripts),
>    - SQL query definitions (optional) and SQL query results (tabular),
> 2) Apply **deterministic bounding rules** so that the evidence passed into the LLM is controlled and repeatable,
> 3) Persist:
>    - the canonical evidence bundle used for the run (as an artifact),
>    - optional â€œfullâ€ artifacts (e.g., full SQL results) separate from â€œboundedâ€ evidence,
> 4) Attach evidence bundle references and summaries to SQL Server run metadata,
> 5) Provide redaction/PII â€œhooksâ€ (minimal, but present) so we can harden later.
>
> Phase 2 is explicitly about â€œevidence packaging,â€ not â€œsmart retrieval.â€ We are not doing embeddings, vector stores, or relevance ranking beyond basic deterministic heuristics.
>
> ---
>
> # 2) Strict Non-Goals
>
> Do NOT implement:
> - Vector embeddings generation or vector DB indexing (Phase 3)
> - Web search / web crawling / snapshotting (Phase 4)
> - Multi-model adjudication (Phase 5)
> - Full taxonomy governance (Phase 6+)
> - Broad refactors across ingest pipeline unless required for compatibility
>
> Keep changes additive and aligned with existing conventions.
>
> ---
>
> # 3) Deliverables (Must be included in this PR)
>
> ## A) Evidence object model + bundle schema (contract-first)
>
> ### A1) Add/Refine Pydantic contracts
> Under `src/llm/contracts/` add or refine Pydantic models for:
>
> 1) `EvidenceItem`
>    Required fields:
>    - `evidence_id: str` (stable within a bundle; deterministic naming preferred)
>    - `evidence_type: str` (enum-like: `inline_text`, `lake_text`, `lake_http`, `sql_result`, `sql_query_def`, `doc_chunk`, `transcript_chunk`, etc.)
>    - `source_ref: dict` (source identity metadata; e.g., `{"lake_uri": "...", "url": "...", "sql": {...}}`)
>    - `content: str` (the bounded text content actually provided to the LLM)
>    - `content_sha256: str` (hash of `content`)
>    - `byte_count: int`
>    - `metadata: dict` (row counts, mime type, offsets, etc.)
>
>    Optional fields:
>    - `offsets: dict | None` (e.g., line ranges, byte ranges, chunk index)
>    - `full_ref: dict | None` (pointer to full unbounded artifact if stored separately)
>
> 2) `EvidenceBundle`
>    Required fields:
>    - `bundle_id: UUID`
>    - `created_utc`
>    - `build_version` (evidence builder version string)
>    - `policy` (bounding policy; see below)
>    - `items: list[EvidenceItem]`
>    - `summary: dict` (counts by evidence_type, total bytes, approximate token estimate if available)
>
> 3) `EvidencePolicy`
>    Required fields:
>    - max items overall, max bytes overall
>    - max bytes per item
>    - max rows for SQL evidence
>    - chunk sizes / overlaps for chunkable sources
>    - deterministic sampling rules (see section C)
>
> Ensure evidence contracts are versioned and referenced in docs.
>
> ### A2) Keep a stable â€œevidence ID conventionâ€
> Implement a deterministic evidence_id convention such as:
> - `inline:{n}`
> - `lake:{sha256_prefix}:{chunk_index}`
> - `sql:{query_key}:{page_index}:{row_range}`
> - `doc:{doc_id}:{chunk_index}`
>
> Evidence IDs must be stable for a given input and policy.
>
> ---
>
> ## B) Evidence Bundle Builder module (core deliverable)
>
> Create `src/llm/evidence/` with:
>
> 1) `builder.py`
>    - Main entry point: `build_evidence_bundle(job_input, evidence_refs, policy) -> EvidenceBundle`
>    - Produces a bundle with deterministic ordering
>    - Applies bounding policies and redaction hooks
>    - Writes bundle artifact to lake (through artifact writer)
>
> 2) `sources/` (source adapters)
>    - `inline_source.py` (job-provided evidence strings)
>    - `lake_text_source.py` (reads text artifacts by lake_uri)
>    - `lake_http_source.py` (reads raw HTTP response artifacts by lake_uri; extracts usable text)
>    - `sql_r...

</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

ðŸ’¬ We'd love your input! Share your thoughts on Copilot coding agent in our [2 minute survey](https://gh.io/copilot-coding-agent-survey).

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
