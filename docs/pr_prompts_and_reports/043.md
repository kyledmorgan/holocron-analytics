# PR #43: Phase 0: Schema refactor baseline for chat/vector runtime split

## Header

| Field | Value |
|---|---|
| **PR Number** | 43 |
| **Title** | Phase 0: Schema refactor baseline for chat/vector runtime split |
| **URL** | https://github.com/kyledmorgan/holocron-analytics/pull/43 |
| **State** | merged |
| **Created** | 2026-02-10T05:04:32Z |
| **Updated** | 2026-02-10T05:16:10Z |
| **Merged** | 2026-02-10T05:16:10Z |
| **Base branch** | `working_20260115` |
| **Head branch** | `copilot/split-chat-and-vector-runtime` |
| **Merge commit SHA** | `8b7752115efd10c688751e2a19795cf26c4f1099` |

---

## PR Body

Splitting `llm` schema into two independent runtimes: `llm` (chat, text‚Üítext) and `vector` (embeddings, text‚Üívectors). Phase 0 captures legacy state and dependency inventory before any breaking changes.

### Deliverables

- **Legacy snapshot** (`db/legacy_snapshots/llm_vector_subsystem_snapshot.sql`)
  - Fully commented, non-executable DDL for `llm.chunk`, `llm.embedding`, `llm.retrieval`, `llm.retrieval_hit`, `llm.source_registry`
  - Documents purpose, deprecation rationale, and new schema replacements

- **Dependency inventory** (`docs/llm/dependency-inventory-vector-subsystem.md`)
  - SQL objects: no stored procs/views reference vector tables
  - Python: `src/llm/retrieval/` modules only‚Äîall experimental, safe to refactor
  - Chat runtime (`llm.job/run/artifact/evidence_*`): zero vector dependencies

- **Migration notes** (`docs/llm/schema-refactor-migration-notes.md`)
  - Phase 1: Create `vector` schema with `embedding_space` identity, idempotency constraints
  - Phase 2: Cutover and deprecate legacy tables

### What's preserved in `llm`
```
llm.job, llm.run, llm.artifact, llm.evidence_bundle, llm.evidence_item, llm.run_evidence
```

### What moves to `vector` (Phase 1)
```
chunk, embedding, embedding_space (new), retrieval, retrieval_hit, source_registry
```

No tables dropped. No code changes. Chat runtime unaffected.

<!-- START COPILOT CODING AGENT SUFFIX -->



<!-- START COPILOT ORIGINAL PROMPT -->



<details>

<summary>Original prompt</summary>

# Copilot Agent Prompt ‚Äî Holocron: Split Chat Runtime vs Vector Runtime (Schema Refactor + Migration Guardrails)

## Context
We have a SQL Server database **Holocron** with an existing schema **`llm`** primarily designed for **LLM interrogation** (text-in ‚Üí text-out via Ollama), including job queueing, run lineage, evidence bundling, and output artifacts stored in a data lake path (`lake_uri`).

Embeddings and vector retrieval were added later as an ‚Äúinclusive bolt-on‚Äù in the same `llm` schema (`llm.embedding`, `llm.chunk`, `llm.retrieval`, etc.). We have **not meaningfully used** the embeddings subsystem yet, so breaking changes there are acceptable. However, we must **avoid breaking changes** to the existing **chat runtime** (text-in/text-out) and its operational patterns.

We want to split into **two independent runtimes** (separate schemas) with mirrored queue/run patterns but different semantics:
- **`llm` schema:** chat/interrogation runtime only (text in ‚Üí text out)
- **`vector` schema:** vector runtime only (text in ‚Üí embedding vector out + retrieval)

## Objectives (High-Level Vision)
1. **Preserve and protect `llm` (chat runtime)**:
   - No breaking changes to existing chat-based prompt/response flows.
   - Keep `llm.job`, `llm.run`, evidence bundling, and artifact logging intact unless a change is clearly non-breaking.

2. **Start clean for vectors in a new schema `vector`**:
   - We are willing to drop/deprecate existing vector-related tables in `llm` after we capture the legacy state.
   - Create a new, extensible vector schema that supports:
     - Embedding ‚Äúanything‚Äù (chunks derived from documents, SQL query definitions, query results, contracts, tag groups, curated views, etc.).
     - Running experiments across many embedding models and families, including drift testing over time.
     - Storing embeddings in a way that prevents accidental mixing of incompatible ‚Äúembedding spaces‚Äù (dimensions, normalization, model digest/version, transforms).
     - Logging retrievals and hits for audit/evaluation and future analytics.

3. **Migration posture**:
   - Chat runtime must keep working.
   - Vector runtime can be rebuilt cleanly.
   - We need a controlled deprecation/migration plan and an inventory of dependencies (SQL objects + Python code) before deleting anything.

## Key Requirements (Design + Governance)
### A) Create `vector` schema with its own runtime tables
Create schema: `vector`

Create tables (baseline set, designed for extensibility):
- `vector.job`  
  Queue of vector tasks (e.g., CHUNK_SOURCE, EMBED_CHUNKS, REEMBED_SPACE, RETRIEVE_TEST, etc.).  
  Must include: `status`, `priority`, `max_attempts`, `attempt_count`, `available_utc`, `locked_by`, `locked_utc`, `last_error`, and a JSON payload describing the work.
- `vector.run`  
  Execution lineage for vector jobs (worker id, base URL, model identity, options/metrics JSON, error).
- `vector.source_registry`  
  Registry/index state for sources (last indexed time, chunk counts, tags, content_sha256).
- `vector.chunk`  
  Canonical chunk table (source_type, source_ref_json, offsets_json, policy_json, content, content_sha256, byte_count, created_utc).
- `vector.embedding_space`  **(critical)**  
  First-class identity for an embedding ‚Äúspace‚Äù (provider, model_name/tag/digest, dimensions, normalize flag, distance metric, preprocessing policy ref, optional transform ref).  
  This prevents mixing vectors across incompatible spaces and supports multi-family experimentation.
- `vector.embedding`  
  Stores embeddings with lineage:
  - `chunk_id`
  - `embedding_space_id`
  - `input_content_sha256` (must match the chunk version used)
  - `run_id`
  - vector payload (start with `vector_json` as NVARCHAR(MAX); optionally add a future `VECTOR(d)` column after baseline works)
  - `vector_sha256` (fingerprint)
  - `created_utc`
  Include uniqueness constraint: `(chunk_id, embedding_space_id, input_content_sha256)` to keep embeddings idempotent for a given chunk-version + space.
- `vector.retrieval` / `vector.retrieval_hit`  
  Retrieval log:
  - retrieval includes: query_text, embedding_space_id (or query model identity), top_k, filters_json, policy_json, created_utc, optional run_id
  - hits include: retrieval_id, rank, chunk_id, score, metadata_json

### B) Preserve `llm` schema as chat runtime only
- Keep existing tables for chat runtime:
  - `llm.job`, `llm.run`, `llm.artifact`, `llm.evidence_bundle`, `llm.evidence_item`, `llm.run_evidence`
- If chat needs its own chunking for prompt-context assembly later, that should live in `llm` under a chat-specific naming (`llm.context_chunk` / `llm.prompt_context_item`) rather than reusing vector retrieval chunks.

### C) Compatibility / Dependency safety
We must inventory dependencies before dropping old vector tables from `llm`.
- Identify SQL objects (views/procs/functions/jobs) referencing:
  - `llm.embedding`, `llm.chunk`, `llm.retrieval`, `llm.retrieval_hit`, `llm.source_registry`
- Identify...

</details>



<!-- START COPILOT CODING AGENT TIPS -->
---

üí° You can make Copilot smarter by setting up custom instructions, customizing its development environment and configuring Model Context Protocol (MCP) servers. Learn more [Copilot coding agent tips](https://gh.io/copilot-coding-agent-tips) in the docs.

---

## Comments

_No comments._

---

## Review Comments (inline diff)

_No inline review comments._

---

## Copilot Artifacts

_No Copilot artifact indicators detected._
